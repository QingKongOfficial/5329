{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ddf547aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow import keras\n",
    "import torch\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms,datasets \n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import random\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import csv\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, TFBertModel, BertModel\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2afcc1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CSV file and image directory\n",
    "csv_file = 'train_cap_label.csv'\n",
    "image_dir = 'path/to/image/directory'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e684eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from the CSV file\n",
    "data = []\n",
    "with open(csv_file, 'r') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    for row in csv_reader:\n",
    "        if len(row) == 2:\n",
    "            labels = [int(label) - 1 for label in row[0].split() if label.strip()]  # Subtract 1 from labels\n",
    "            caption = row[1]\n",
    "            if labels:  # Only append if there are labels\n",
    "                data.append((labels, caption))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "28c61cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7367dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the captions\n",
    "train_captions = [caption for _, caption in train_data]\n",
    "train_labels = [labels for labels, _ in train_data]\n",
    "test_captions = [caption for _, caption in test_data]\n",
    "test_labels = [labels for labels, _ in test_data]\n",
    "\n",
    "train_encodings = tokenizer(train_captions, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_captions, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "983aa66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoded vectors\n",
    "num_classes = 18  # Number of classes\n",
    "train_labels_onehot = tf.keras.utils.to_categorical([tf.reduce_max(labels) for labels in train_labels], num_classes=num_classes)\n",
    "test_labels_onehot = tf.keras.utils.to_categorical([tf.reduce_max(labels) for labels in test_labels], num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0642c472",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Create the BERT model\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7bfc7ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "input_ids = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='input_ids')\n",
    "attention_mask = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name='attention_mask')\n",
    "bert_output = bert_model(input_ids, attention_mask=attention_mask)\n",
    "pooled_output = bert_output.pooler_output\n",
    "hidden_layer = tf.keras.layers.Dense(32, activation='relu')(pooled_output)\n",
    "output_layer = tf.keras.layers.Dense(num_classes, activation='sigmoid')(hidden_layer)\n",
    "model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0a10da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00002),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c4f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "59/59 [==============================] - 3303s 56s/step - loss: 0.4095 - accuracy: 0.2419 - val_loss: 0.2517 - val_accuracy: 0.4675\n",
      "Epoch 2/3\n",
      "31/59 [==============>...............] - ETA: 19:26 - loss: 0.2362 - accuracy: 0.4744"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "batch_size = 256\n",
    "epochs = 3\n",
    "model.fit(\n",
    "    {'input_ids': np.array(train_encodings['input_ids']),\n",
    "     'attention_mask': np.array(train_encodings['attention_mask'])},\n",
    "    train_labels_onehot,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(\n",
    "        {'input_ids': np.array(test_encodings['input_ids']),\n",
    "         'attention_mask': np.array(test_encodings['attention_mask'])},\n",
    "        test_labels_onehot\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83092453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on the test set\n",
    "test_predictions = model.predict(\n",
    "    {'input_ids': np.array(test_encodings['input_ids']),\n",
    "     'attention_mask': np.array(test_encodings['attention_mask'])}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0d1943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to binary labels\n",
    "threshold = 0.5\n",
    "binary_predictions = np.where(test_predictions >= threshold, 1, 0)\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1 = f1_score(test_labels, binary_predictions, average='micro')\n",
    "print(f'F1-score: {f1:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
