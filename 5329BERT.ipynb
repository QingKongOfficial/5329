{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95d532eb-9e97-4f61-b6a0-209c5733bd4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement CSV (from versions: none)\n",
      "ERROR: No matching distribution found for CSV\n"
     ]
    }
   ],
   "source": [
    "pip install CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90792f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow import keras\n",
    "import torch\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms,datasets \n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import random\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import csv\n",
    "from PIL import Image\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe9dff8-2e29-4e78-ab97-35ff259dca18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7372b56f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58ab7e11-d491-459d-a9f3-db4c5505b666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiLabelImageDataset(keras.utils.Sequence):\n",
    "    def __init__(self, image_dir, label_file, num_classes, tokenizer, max_length, batch_size=32, shuffle=True, subset='train'):\n",
    "        self.image_dir = image_dir\n",
    "        self.num_classes = num_classes\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.subset = subset\n",
    "        self.data = []\n",
    "        \n",
    "        # Load labels and captions from the CSV file\n",
    "        with open(label_file, 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                image_id, labels_str, caption = row\n",
    "                labels = [int(label) for label in labels_str.split()]\n",
    "                self.data.append((os.path.join(image_dir, f\"{image_id}.jpg\"), labels, caption))\n",
    "        \n",
    "        # Split the data into train and test sets\n",
    "        random.shuffle(self.data)\n",
    "        split_idx = int(len(self.data) * 0.8)  # 80% for training, 20% for testing\n",
    "        if self.subset == 'train':\n",
    "            self.data = self.data[:split_idx]\n",
    "        else:\n",
    "            self.data = self.data[split_idx:]\n",
    "        \n",
    "        self.indexes = np.arange(len(self.data))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.data) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_indexes = self.indexes[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_images = []\n",
    "        batch_text = []\n",
    "        batch_targets = []\n",
    "        for i in batch_indexes:\n",
    "            image_path, labels, caption = self.data[i]\n",
    "\n",
    "            # Load and preprocess the image\n",
    "            img = Image.open(image_path)\n",
    "            img = img.resize((224, 224))\n",
    "            img = np.array(img)\n",
    "            img = keras.applications.resnet50.preprocess_input(img)\n",
    "            batch_images.append(img)\n",
    "\n",
    "            # Tokenize and encode the caption\n",
    "            encoded_caption = self.tokenizer.encode_plus(\n",
    "                caption,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_attention_mask=True,\n",
    "                return_token_type_ids=False,\n",
    "                return_tensors='tf'\n",
    "            )\n",
    "            batch_text.append(encoded_caption['input_ids'][0])  # Extract the input IDs from the encoded caption\n",
    "\n",
    "            # Convert labels to a one-hot encoded numpy array\n",
    "            target = np.zeros(self.num_classes)\n",
    "            for label in labels:\n",
    "                target[label - 1] = 1\n",
    "            batch_targets.append(target)\n",
    "\n",
    "        batch_images = np.array(batch_images)\n",
    "        batch_text = np.array(batch_text)\n",
    "        batch_targets = np.array(batch_targets)\n",
    "\n",
    "        return (batch_images, batch_text), batch_targets  # Return a tuple of inputs and targets\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "665fe6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer_ = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_length = 128  # Maximum sequence length for the text input\n",
    "\n",
    "train_dataset = MultiLabelImageDataset(label_file='train.csv', image_dir = 'data/', num_classes = 18, tokenizer=tokenizer_ , max_length = 128, batch_size=32, subset='train')\n",
    "test_dataset = MultiLabelImageDataset(label_file='train.csv', image_dir = 'data/', num_classes = 18, tokenizer=tokenizer_ , max_length = 128, batch_size=32, subset='test')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "dc2e64cc-172b-4f23-99db-545e32033388",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3229d5c7ea44e69a1825f63a41fa3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/45.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.pooler.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.1.output.LayerNorm.weight', 'cls.seq_relationship.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'bert.pooler.dense.bias', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'cls.predictions.decoder.weight', 'bert.encoder.layer.3.intermediate.dense.weight', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.embeddings.word_embeddings.weight', 'cls.predictions.decoder.bias', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.embeddings.token_type_embeddings.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.output.dense.weight', 'cls.predictions.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.embeddings.position_embeddings.weight', 'cls.seq_relationship.bias', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertModel were not initialized from the PyTorch model and are newly initialized: ['tf_bert_model_4.bert.embeddings.word_embeddings.weight', 'tf_bert_model_4.bert.embeddings.token_type_embeddings.weight', 'tf_bert_model_4.bert.embeddings.position_embeddings.weight', 'tf_bert_model_4.bert.embeddings.LayerNorm.weight', 'tf_bert_model_4.bert.embeddings.LayerNorm.bias', 'tf_bert_model_4.bert.encoder.layer.0.attention.self.query.weight', 'tf_bert_model_4.bert.encoder.layer.0.attention.self.query.bias', 'tf_bert_model_4.bert.encoder.layer.0.attention.self.key.weight', 'tf_bert_model_4.bert.encoder.layer.0.attention.self.key.bias', 'tf_bert_model_4.bert.encoder.layer.0.attention.self.value.weight', 'tf_bert_model_4.bert.encoder.layer.0.attention.self.value.bias', 'tf_bert_model_4.bert.encoder.layer.0.attention.output.dense.weight', 'tf_bert_model_4.bert.encoder.layer.0.attention.output.dense.bias', 'tf_bert_model_4.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'tf_bert_model_4.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'tf_bert_model_4.bert.encoder.layer.0.intermediate.dense.weight', 'tf_bert_model_4.bert.encoder.layer.0.intermediate.dense.bias', 'tf_bert_model_4.bert.encoder.layer.0.output.dense.weight', 'tf_bert_model_4.bert.encoder.layer.0.output.dense.bias', 'tf_bert_model_4.bert.encoder.layer.0.output.LayerNorm.weight', 'tf_bert_model_4.bert.encoder.layer.0.output.LayerNorm.bias', 'tf_bert_model_4.bert.encoder.layer.1.attention.self.query.weight', 'tf_bert_model_4.bert.encoder.layer.1.attention.self.query.bias', 'tf_bert_model_4.bert.encoder.layer.1.attention.self.key.weight', 'tf_bert_model_4.bert.encoder.layer.1.attention.self.key.bias', 'tf_bert_model_4.bert.encoder.layer.1.attention.self.value.weight', 'tf_bert_model_4.bert.encoder.layer.1.attention.self.value.bias', 'tf_bert_model_4.bert.encoder.layer.1.attention.output.dense.weight', 'tf_bert_model_4.bert.encoder.layer.1.attention.output.dense.bias', 'tf_bert_model_4.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'tf_bert_model_4.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'tf_bert_model_4.bert.encoder.layer.1.intermediate.dense.weight', 'tf_bert_model_4.bert.encoder.layer.1.intermediate.dense.bias', 'tf_bert_model_4.bert.encoder.layer.1.output.dense.weight', 'tf_bert_model_4.bert.encoder.layer.1.output.dense.bias', 'tf_bert_model_4.bert.encoder.layer.1.output.LayerNorm.weight', 'tf_bert_model_4.bert.encoder.layer.1.output.LayerNorm.bias', 'tf_bert_model_4.bert.encoder.layer.2.attention.self.query.weight', 'tf_bert_model_4.bert.encoder.layer.2.attention.self.query.bias', 'tf_bert_model_4.bert.encoder.layer.2.attention.self.key.weight', 'tf_bert_model_4.bert.encoder.layer.2.attention.self.key.bias', 'tf_bert_model_4.bert.encoder.layer.2.attention.self.value.weight', 'tf_bert_model_4.bert.encoder.layer.2.attention.self.value.bias', 'tf_bert_model_4.bert.encoder.layer.2.attention.output.dense.weight', 'tf_bert_model_4.bert.encoder.layer.2.attention.output.dense.bias', 'tf_bert_model_4.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'tf_bert_model_4.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'tf_bert_model_4.bert.encoder.layer.2.intermediate.dense.weight', 'tf_bert_model_4.bert.encoder.layer.2.intermediate.dense.bias', 'tf_bert_model_4.bert.encoder.layer.2.output.dense.weight', 'tf_bert_model_4.bert.encoder.layer.2.output.dense.bias', 'tf_bert_model_4.bert.encoder.layer.2.output.LayerNorm.weight', 'tf_bert_model_4.bert.encoder.layer.2.output.LayerNorm.bias', 'tf_bert_model_4.bert.encoder.layer.3.attention.self.query.weight', 'tf_bert_model_4.bert.encoder.layer.3.attention.self.query.bias', 'tf_bert_model_4.bert.encoder.layer.3.attention.self.key.weight', 'tf_bert_model_4.bert.encoder.layer.3.attention.self.key.bias', 'tf_bert_model_4.bert.encoder.layer.3.attention.self.value.weight', 'tf_bert_model_4.bert.encoder.layer.3.attention.self.value.bias', 'tf_bert_model_4.bert.encoder.layer.3.attention.output.dense.weight', 'tf_bert_model_4.bert.encoder.layer.3.attention.output.dense.bias', 'tf_bert_model_4.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'tf_bert_model_4.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'tf_bert_model_4.bert.encoder.layer.3.intermediate.dense.weight', 'tf_bert_model_4.bert.encoder.layer.3.intermediate.dense.bias', 'tf_bert_model_4.bert.encoder.layer.3.output.dense.weight', 'tf_bert_model_4.bert.encoder.layer.3.output.dense.bias', 'tf_bert_model_4.bert.encoder.layer.3.output.LayerNorm.weight', 'tf_bert_model_4.bert.encoder.layer.3.output.LayerNorm.bias', 'tf_bert_model_4.bert.pooler.dense.weight', 'tf_bert_model_4.bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['bert.encoder.layer.2.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.attention.self.key.bias', 'bert.pooler.dense.weight', 'bert.encoder.layer.2.output.dense.bias', 'bert.encoder.layer.0.attention.self.key.weight', 'fit_denses.0.weight', 'bert.encoder.layer.2.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.bias', 'bert.encoder.layer.2.attention.self.value.bias', 'bert.encoder.layer.0.attention.output.dense.bias', 'bert.encoder.layer.2.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.intermediate.dense.weight', 'bert.encoder.layer.1.output.LayerNorm.weight', 'cls.seq_relationship.weight', 'fit_denses.4.weight', 'fit_denses.3.weight', 'bert.encoder.layer.1.attention.self.key.bias', 'bert.encoder.layer.2.intermediate.dense.bias', 'bert.encoder.layer.1.output.LayerNorm.bias', 'bert.encoder.layer.3.attention.self.key.weight', 'fit_denses.2.weight', 'bert.pooler.dense.bias', 'fit_denses.1.weight', 'bert.encoder.layer.3.intermediate.dense.bias', 'bert.encoder.layer.0.attention.self.value.weight', 'cls.predictions.decoder.weight', 'bert.encoder.layer.3.intermediate.dense.weight', 'cls.predictions.transform.dense.bias', 'bert.encoder.layer.1.attention.self.query.weight', 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.1.intermediate.dense.weight', 'bert.encoder.layer.3.attention.self.value.bias', 'bert.encoder.layer.3.attention.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.value.weight', 'bert.encoder.layer.1.attention.output.LayerNorm.bias', 'bert.encoder.layer.0.attention.self.query.bias', 'bert.embeddings.word_embeddings.weight', 'bert.encoder.layer.3.attention.self.query.bias', 'bert.embeddings.token_type_embeddings.weight', 'cls.predictions.transform.dense.weight', 'fit_denses.0.bias', 'cls.predictions.transform.LayerNorm.weight', 'bert.encoder.layer.0.output.dense.bias', 'bert.encoder.layer.3.output.dense.bias', 'bert.encoder.layer.1.output.dense.weight', 'fit_denses.3.bias', 'fit_denses.4.bias', 'bert.encoder.layer.0.attention.self.value.bias', 'bert.encoder.layer.3.attention.self.query.weight', 'bert.encoder.layer.1.output.dense.bias', 'bert.encoder.layer.0.output.LayerNorm.weight', 'bert.encoder.layer.1.attention.self.query.bias', 'bert.encoder.layer.3.output.dense.weight', 'bert.encoder.layer.2.attention.self.value.weight', 'bert.encoder.layer.1.attention.self.value.bias', 'bert.encoder.layer.1.attention.output.LayerNorm.weight', 'bert.encoder.layer.2.output.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.weight', 'bert.encoder.layer.3.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.output.dense.weight', 'fit_denses.1.bias', 'bert.encoder.layer.2.attention.self.query.weight', 'bert.encoder.layer.3.attention.output.LayerNorm.weight', 'bert.encoder.layer.0.output.dense.weight', 'cls.predictions.bias', 'bert.encoder.layer.0.attention.self.query.weight', 'bert.encoder.layer.1.attention.output.dense.bias', 'bert.encoder.layer.0.intermediate.dense.weight', 'bert.encoder.layer.0.attention.self.key.bias', 'bert.encoder.layer.2.output.LayerNorm.weight', 'bert.embeddings.LayerNorm.bias', 'fit_denses.2.bias', 'bert.encoder.layer.3.output.LayerNorm.weight', 'bert.encoder.layer.2.attention.self.query.bias', 'bert.encoder.layer.0.intermediate.dense.bias', 'bert.encoder.layer.1.attention.output.dense.weight', 'bert.embeddings.position_embeddings.weight', 'cls.seq_relationship.bias', 'bert.encoder.layer.1.intermediate.dense.bias', 'bert.encoder.layer.2.attention.self.key.weight', 'bert.encoder.layer.0.output.LayerNorm.bias', 'bert.encoder.layer.1.attention.self.key.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.bias', 'bert.encoder.layer.2.attention.self.key.bias', 'bert.encoder.layer.3.attention.self.value.weight', 'bert.encoder.layer.0.attention.output.dense.weight', 'bert.encoder.layer.3.attention.output.dense.weight', 'bert.encoder.layer.2.attention.output.dense.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertModel were not initialized from the PyTorch model and are newly initialized: ['tf_bert_model_5.bert.embeddings.word_embeddings.weight', 'tf_bert_model_5.bert.embeddings.token_type_embeddings.weight', 'tf_bert_model_5.bert.embeddings.position_embeddings.weight', 'tf_bert_model_5.bert.embeddings.LayerNorm.weight', 'tf_bert_model_5.bert.embeddings.LayerNorm.bias', 'tf_bert_model_5.bert.encoder.layer.0.attention.self.query.weight', 'tf_bert_model_5.bert.encoder.layer.0.attention.self.query.bias', 'tf_bert_model_5.bert.encoder.layer.0.attention.self.key.weight', 'tf_bert_model_5.bert.encoder.layer.0.attention.self.key.bias', 'tf_bert_model_5.bert.encoder.layer.0.attention.self.value.weight', 'tf_bert_model_5.bert.encoder.layer.0.attention.self.value.bias', 'tf_bert_model_5.bert.encoder.layer.0.attention.output.dense.weight', 'tf_bert_model_5.bert.encoder.layer.0.attention.output.dense.bias', 'tf_bert_model_5.bert.encoder.layer.0.attention.output.LayerNorm.weight', 'tf_bert_model_5.bert.encoder.layer.0.attention.output.LayerNorm.bias', 'tf_bert_model_5.bert.encoder.layer.0.intermediate.dense.weight', 'tf_bert_model_5.bert.encoder.layer.0.intermediate.dense.bias', 'tf_bert_model_5.bert.encoder.layer.0.output.dense.weight', 'tf_bert_model_5.bert.encoder.layer.0.output.dense.bias', 'tf_bert_model_5.bert.encoder.layer.0.output.LayerNorm.weight', 'tf_bert_model_5.bert.encoder.layer.0.output.LayerNorm.bias', 'tf_bert_model_5.bert.encoder.layer.1.attention.self.query.weight', 'tf_bert_model_5.bert.encoder.layer.1.attention.self.query.bias', 'tf_bert_model_5.bert.encoder.layer.1.attention.self.key.weight', 'tf_bert_model_5.bert.encoder.layer.1.attention.self.key.bias', 'tf_bert_model_5.bert.encoder.layer.1.attention.self.value.weight', 'tf_bert_model_5.bert.encoder.layer.1.attention.self.value.bias', 'tf_bert_model_5.bert.encoder.layer.1.attention.output.dense.weight', 'tf_bert_model_5.bert.encoder.layer.1.attention.output.dense.bias', 'tf_bert_model_5.bert.encoder.layer.1.attention.output.LayerNorm.weight', 'tf_bert_model_5.bert.encoder.layer.1.attention.output.LayerNorm.bias', 'tf_bert_model_5.bert.encoder.layer.1.intermediate.dense.weight', 'tf_bert_model_5.bert.encoder.layer.1.intermediate.dense.bias', 'tf_bert_model_5.bert.encoder.layer.1.output.dense.weight', 'tf_bert_model_5.bert.encoder.layer.1.output.dense.bias', 'tf_bert_model_5.bert.encoder.layer.1.output.LayerNorm.weight', 'tf_bert_model_5.bert.encoder.layer.1.output.LayerNorm.bias', 'tf_bert_model_5.bert.encoder.layer.2.attention.self.query.weight', 'tf_bert_model_5.bert.encoder.layer.2.attention.self.query.bias', 'tf_bert_model_5.bert.encoder.layer.2.attention.self.key.weight', 'tf_bert_model_5.bert.encoder.layer.2.attention.self.key.bias', 'tf_bert_model_5.bert.encoder.layer.2.attention.self.value.weight', 'tf_bert_model_5.bert.encoder.layer.2.attention.self.value.bias', 'tf_bert_model_5.bert.encoder.layer.2.attention.output.dense.weight', 'tf_bert_model_5.bert.encoder.layer.2.attention.output.dense.bias', 'tf_bert_model_5.bert.encoder.layer.2.attention.output.LayerNorm.weight', 'tf_bert_model_5.bert.encoder.layer.2.attention.output.LayerNorm.bias', 'tf_bert_model_5.bert.encoder.layer.2.intermediate.dense.weight', 'tf_bert_model_5.bert.encoder.layer.2.intermediate.dense.bias', 'tf_bert_model_5.bert.encoder.layer.2.output.dense.weight', 'tf_bert_model_5.bert.encoder.layer.2.output.dense.bias', 'tf_bert_model_5.bert.encoder.layer.2.output.LayerNorm.weight', 'tf_bert_model_5.bert.encoder.layer.2.output.LayerNorm.bias', 'tf_bert_model_5.bert.encoder.layer.3.attention.self.query.weight', 'tf_bert_model_5.bert.encoder.layer.3.attention.self.query.bias', 'tf_bert_model_5.bert.encoder.layer.3.attention.self.key.weight', 'tf_bert_model_5.bert.encoder.layer.3.attention.self.key.bias', 'tf_bert_model_5.bert.encoder.layer.3.attention.self.value.weight', 'tf_bert_model_5.bert.encoder.layer.3.attention.self.value.bias', 'tf_bert_model_5.bert.encoder.layer.3.attention.output.dense.weight', 'tf_bert_model_5.bert.encoder.layer.3.attention.output.dense.bias', 'tf_bert_model_5.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'tf_bert_model_5.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'tf_bert_model_5.bert.encoder.layer.3.intermediate.dense.weight', 'tf_bert_model_5.bert.encoder.layer.3.intermediate.dense.bias', 'tf_bert_model_5.bert.encoder.layer.3.output.dense.weight', 'tf_bert_model_5.bert.encoder.layer.3.output.dense.bias', 'tf_bert_model_5.bert.encoder.layer.3.output.LayerNorm.weight', 'tf_bert_model_5.bert.encoder.layer.3.output.LayerNorm.bias', 'tf_bert_model_5.bert.pooler.dense.weight', 'tf_bert_model_5.bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    " # Load ResNet50 model with pre-trained weights\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    " # Load BERTmini model from pre-trained weights\n",
    "bertmini_model = TFBertModel.from_pretrained('google/bert_uncased_L-4_H-256_A-4', from_pt=True)\n",
    "    \n",
    " # Load TinyBERT model\n",
    "tinybert_model = TFBertModel.from_pretrained('huawei-noah/TinyBERT_General_4L_312D', from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6d8b0717-007f-4ae6-9f1b-b49c4b1335f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Freeze the ResNet50 and TinyBERT layers\n",
    "#for layer in resnet_model.layers:\n",
    "#    layer.trainable = False\n",
    "#for layer in tinybert_model.layers:\n",
    "#    layer.trainable = False\n",
    "\n",
    "# Fine-tune the ResNet50 and TinyBERT models\n",
    "for layer in resnet_model.layers[:]:\n",
    "    layer.trainable = False\n",
    "for layer in tinybert_model.layers[:]:\n",
    "    layer.trainable = False\n",
    "for layer in bertmini_model.layers[:]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "586f0d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the image input\n",
    "image_input = keras.Input(shape=(224, 224, 3))\n",
    "image_features = resnet_model(image_input)\n",
    "image_features = keras.layers.GlobalAveragePooling2D()(image_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a9a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "605ce39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the text input\n",
    "text_input = keras.Input(shape=(max_length,), dtype=tf.int32)\n",
    "text_features = bertmini_model(text_input)[1]  # Use the pooled output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "5d24c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the image and text features\n",
    "combined_features = keras.layers.concatenate([image_features, text_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a86cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "39352213",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = keras.layers.Dense(18, activation='sigmoid')(combined_features) # num_classes is 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0a8f5253-2ed2-4154-8045-81889bfa18db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the final model\n",
    "model = keras.models.Model(inputs=[image_input, text_input], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a8beb725-637f-460e-b21c-c252a0bb2be8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compile the model with a custom learning rate\n",
    "learning_rate = 0.00002\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7260ef-02a3-41e8-b2ee-c965e7217dfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - ETA: 0s - loss: 0.1225 - accuracy: 0.7967"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 1\n",
    "model.fit(\n",
    "        train_dataset,\n",
    "        validation_data=test_dataset,\n",
    "        epochs=epochs,\n",
    "        workers=1,\n",
    "        use_multiprocessing=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7942f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 340s 2s/step - loss: 0.0821 - accuracy: 0.8200\n",
      "Test Loss: 0.0821\n",
      "Test Accuracy: 0.8200\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "597cf62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a395fc-928e-404c-97ba-12c30b9685d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e74c900-615e-45ff-aeab-e5df5b1ebfeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76661fb0-7df9-44a6-af43-7d66cbe5ad89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
